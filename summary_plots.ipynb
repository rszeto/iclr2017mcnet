{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import os\n",
    "import imageio\n",
    "import glob\n",
    "import argparse\n",
    "from IPython.display import Image\n",
    "from IPython.display import HTML\n",
    "from IPython.display import Markdown\n",
    "\n",
    "RESULTS_ROOTS = {\n",
    "    'mcnet': os.path.join('results', 'quantitative', 'MNIST'),\n",
    "    'prednet': os.path.join('prednet', 'mnist_results', 'quantitative', 'MNIST')\n",
    "}\n",
    "\n",
    "IMAGE_ROOTS = {\n",
    "    'mcnet': os.path.join('results', 'images', 'MNIST'),\n",
    "    'prednet': os.path.join('prednet', 'mnist_results', 'images', 'MNIST')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Display utils\n",
    "'''\n",
    "\n",
    "def show_gif(gif_path):\n",
    "    display(HTML('<img src=\"%s\">' % gif_path))\n",
    "\n",
    "def show_image_row(image_paths, image_titles):\n",
    "    assert(len(image_paths) == len(image_titles))\n",
    "    html = '<table><tr>'\n",
    "    for i in xrange(len(image_titles)):\n",
    "        html += '<td style=\"text-align:center\">%s</td>' % str(image_titles[i])\n",
    "    html += '</tr><tr>'\n",
    "    for i in xrange(len(image_paths)):\n",
    "        html += '<td><img src=\"%s\"></td>' \\\n",
    "            % (image_paths[i])\n",
    "    html += '</tr></table>'\n",
    "    \n",
    "    display(HTML(html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_results(arch, dataset_label, model_label):\n",
    "    results_dir = os.path.join(RESULTS_ROOTS[arch], 'data=%s' % dataset_label, 'model=%s' % model_label)\n",
    "    if not os.path.isdir(results_dir):\n",
    "        raise RuntimeError('Path does not exist: %s' % results_dir)\n",
    "    results_file_arr = filter(lambda x: x.endswith('.npz'), os.listdir(results_dir))\n",
    "    if len(results_file_arr) == 0:\n",
    "        raise RuntimeError('No results file found in path %s' % results_dir)\n",
    "    elif len(results_file_arr) > 1:\n",
    "        raise RuntimeError('Too many results files found in path %s' % results_dir)\n",
    "    results_file_path = os.path.join(results_dir, results_file_arr[0])\n",
    "    return np.load(results_file_path)\n",
    "\n",
    "\n",
    "def get_sorted_videos_by_metric(arch, dataset_label, model_label, metric):\n",
    "    results = get_results(arch, dataset_label, model_label)\n",
    "    metric_vals = results[metric]\n",
    "    metric_aucs = np.sum(metric_vals, axis=1)\n",
    "    sorted_idx = np.argsort(metric_aucs)\n",
    "    return sorted_idx, metric_aucs[sorted_idx]\n",
    "\n",
    "\n",
    "def plot_sorted_auc(ax, arch, dataset_label, model_label, metric, label):\n",
    "    # Plot\n",
    "    _, sorted_metric_aucs = get_sorted_videos_by_metric(arch, dataset_label, model_label, metric)\n",
    "    ax.plot(xrange(len(sorted_metric_aucs)), sorted_metric_aucs, label=label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure()\n",
    "# ax1 = fig.add_subplot(111)\n",
    "# plot_sorted_auc(ax1, 'prednet', 'flashing=async_b+num_digits=2', 'flashing=async_b+num_digits=2', 'ssim', None)\n",
    "# plot_sorted_auc(ax1, 'prednet', 'flashing=async_b+num_digits=2', 'flashing=async_a+num_digits=2', 'ssim', None)\n",
    "# ax1.set_xlim([0, 1000])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_arch_comparison(dataset_label, model_label, metric):\n",
    "    fig = plt.figure()\n",
    "    ax1 = fig.add_subplot(111)\n",
    "    for arch in RESULTS_ROOTS.iterkeys():\n",
    "        plot_sorted_auc(ax1, arch, dataset_label, model_label, metric, arch)\n",
    "    ax1.set_xlabel('Instance #')\n",
    "    ax1.set_ylabel('%s AUC' % metric.upper())\n",
    "    ax1.legend(loc='best')\n",
    "    ax1.set_title('Architecture comparison\\nTraining set: %s\\nTesting set: %s' % (model_label, dataset_label))\n",
    "    plt.show()\n",
    "\n",
    "# plot_arch_comparison('flashing=async_b+num_digits=2', 'flashing=async_a+num_digits=2', 'ssim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_training_set_comparison(dataset_label, metric):\n",
    "    fig = plt.figure()\n",
    "    ax1 = fig.add_subplot(111)\n",
    "    \n",
    "    # Find all models trained on this dataset\n",
    "    for arch in RESULTS_ROOTS.iterkeys():\n",
    "        dataset_results_root = os.path.join(RESULTS_ROOTS[arch], 'data=%s' % dataset_label)\n",
    "        if not os.path.isdir(dataset_results_root):\n",
    "            continue\n",
    "        model_labels = [x.replace('model=', '') for x in os.listdir(dataset_results_root)]\n",
    "\n",
    "        # Plot\n",
    "        for model_label in model_labels:\n",
    "            try:\n",
    "                plot_sorted_auc(ax1, arch, dataset_label, model_label, metric, 'arch=%s,train=%s' % (arch, model_label))\n",
    "            except RuntimeError:\n",
    "                pass\n",
    "    \n",
    "    # Format plot\n",
    "    ax1.set_xlabel('Instance #')\n",
    "    ax1.set_ylabel('%s AUC' % metric.upper())\n",
    "    ax1.set_ylim([4, 5.1])\n",
    "    ax1.legend(loc='lower left', bbox_to_anchor=(1, 0))\n",
    "    ax1.set_title('Training set comparison\\nTesting set: %s' % dataset_label)\n",
    "    plt.show()\n",
    "\n",
    "# plot_training_set_comparison('flashing=async_b+num_digits=2', 'ssim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_test_dataset_labels = [x.replace('data=', '') for x in os.listdir(RESULTS_ROOTS['mcnet'])]\n",
    "for dataset_label in all_test_dataset_labels:\n",
    "    plot_training_set_comparison(dataset_label, 'ssim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_experiment(arch, dataset_label, model_label, metric):\n",
    "    display(HTML('<hr style=\"height:2px\">'))\n",
    "    display(HTML('<span style=\"font-weight:bold;font-size:20px\">Architecture: %s<br>Train:%s<br>Test:%s</span>' \\\n",
    "                % (arch, model_label, dataset_label)))\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    ax1 = fig.add_subplot(111)\n",
    "    plot_sorted_auc(ax1, arch, dataset_label, model_label, metric, None)\n",
    "    ax1.set_xlabel('Instance #')\n",
    "    ax1.set_ylabel('%s AUC' % metric.upper())\n",
    "#     ax1.set_ylim([3.5, 5.1])\n",
    "    ax1.legend(loc='lower left', bbox_to_anchor=(1, 0))\n",
    "    plt.show()\n",
    "    \n",
    "    sorted_idx, _ = get_sorted_videos_by_metric(arch, dataset_label, model_label, metric)\n",
    "    print('Worst videos:')\n",
    "    image_paths = [os.path.join(IMAGE_ROOTS[arch], 'data=%s' % dataset_label, 'model=%s' % model_label, 'both_%04d.gif' % i) for i in sorted_idx[:5]]\n",
    "    show_image_row(image_paths, sorted_idx[:5])\n",
    "    print('Best videos:')\n",
    "    image_paths = [os.path.join(IMAGE_ROOTS[arch], 'data=%s' % dataset_label, 'model=%s' % model_label, 'both_%04d.gif' % i) for i in sorted_idx[-5:]]\n",
    "    show_image_row(image_paths, sorted_idx[-5:])\n",
    "\n",
    "# summarize_experiment('mcnet', 'translation=on+num_digits=2', 'translation=on', 'ssim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for arch in RESULTS_ROOTS.iterkeys():\n",
    "    dataset_labels = [x.replace('data=', '') for x in os.listdir(RESULTS_ROOTS[arch])]\n",
    "    for dataset_label in dataset_labels:\n",
    "        model_labels = [x.replace('model=', '') for x in os.listdir(os.path.join(RESULTS_ROOTS[arch], 'data=%s' % dataset_label))]\n",
    "        for model_label in model_labels:\n",
    "            try:\n",
    "                summarize_experiment(arch, dataset_label, model_label, 'ssim')\n",
    "            except RuntimeError:\n",
    "                print('Skipping %s' % ((arch, dataset_label, model_label),))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
