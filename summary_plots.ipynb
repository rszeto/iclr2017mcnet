{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import os\n",
    "import imageio\n",
    "import glob\n",
    "import argparse\n",
    "from pprint import pprint\n",
    "from warnings import warn\n",
    "from scipy.stats import zscore\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.display import HTML\n",
    "from IPython.display import Markdown\n",
    "from IPython.display import display\n",
    "\n",
    "ARCHS = ['mcnet', 'prednet', 'drnet']\n",
    "\n",
    "RESULTS_ROOTS = {\n",
    "    'mcnet': os.path.join('results', 'quantitative', 'MNIST'),\n",
    "    'prednet': os.path.join('prednet', 'mnist_results', 'quantitative', 'MNIST'),\n",
    "    'drnet': os.path.join('drnet', 'results', 'MNIST', 'quantitative')\n",
    "}\n",
    "\n",
    "IMAGE_ROOTS = {\n",
    "    'mcnet': os.path.join('results', 'images', 'MNIST'),\n",
    "    'prednet': os.path.join('prednet', 'mnist_results', 'images', 'MNIST'),\n",
    "    'drnet': os.path.join('drnet', 'results', 'MNIST', 'images')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Display utils\n",
    "'''\n",
    "\n",
    "def get_gif_path(arch, dataset_label, model_label, video_idx):\n",
    "    return os.path.join(IMAGE_ROOTS[arch], 'data=%s' % dataset_label,\n",
    "                        'model=%s' % model_label, 'both_%04d.gif' % video_idx)\n",
    "\n",
    "def show_image_row(image_paths, image_titles):\n",
    "    assert(len(image_paths) == len(image_titles))\n",
    "    html = '<table><tr>'\n",
    "    for i in xrange(len(image_titles)):\n",
    "        html += '<td style=\"text-align:center\">%s</td>' % str(image_titles[i])\n",
    "    html += '</tr><tr>'\n",
    "    for i in xrange(len(image_paths)):\n",
    "        html += '<td><img src=\"%s\"></td>' \\\n",
    "            % (image_paths[i])\n",
    "    html += '</tr></table>'\n",
    "    \n",
    "    display(HTML(html))\n",
    "\n",
    "def visualize_videos(arch, dataset_label, model_label, sorted_idx):\n",
    "    print('Worst videos:')\n",
    "    image_paths = [get_gif_path(arch, dataset_label, model_label, i) for i in sorted_idx[:5]]\n",
    "    show_image_row(image_paths, sorted_idx[:5])\n",
    "    print('Middle videos:')\n",
    "    mid_lower = len(sorted_idx) / 2 - 2\n",
    "    mid_upper = len(sorted_idx) / 2 + 3\n",
    "    image_paths = [get_gif_path(arch, dataset_label, model_label, i) for i in sorted_idx[mid_lower:mid_upper]]\n",
    "    show_image_row(image_paths, sorted_idx[mid_lower:mid_upper])\n",
    "    print('Best videos:')\n",
    "    image_paths = [get_gif_path(arch, dataset_label, model_label, i) for i in sorted_idx[-5:]]\n",
    "    show_image_row(image_paths, sorted_idx[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_experiments():\n",
    "    '''\n",
    "    Prepare a dictionary listing all the combinations of architecture, training set, and test set found\n",
    "    in the result paths. Also prints warnings for inconsistencies like missing output videos or experi-\n",
    "    ments only found for one architecture.\n",
    "    '''\n",
    "    \n",
    "    ret = {arch: {} for arch in ARCHS}\n",
    "    for arch in ARCHS:\n",
    "        dataset_labels = [x.replace('data=', '') for x in os.listdir(RESULTS_ROOTS[arch])]\n",
    "        if len(dataset_labels) == 0:\n",
    "            warn('No datasets found for architecture %s, skipping' % arch)\n",
    "        else:\n",
    "            for dataset_label in dataset_labels:\n",
    "                model_labels = [x.replace('model=', '') \n",
    "                               for x in os.listdir(os.path.join(RESULTS_ROOTS[arch], 'data=%s' % dataset_label))]\n",
    "                if len(model_labels) == 0:\n",
    "                    warn('No models found for architecture %s, data %s. Skipping' % (arch, dataset_label))\n",
    "                else:\n",
    "                    ret[arch][dataset_label] = model_labels\n",
    "    \n",
    "    # Check that each architecture has the same datasets\n",
    "    print('Comparing dataset %s with dataset %s' % (ARCHS[0], ARCHS[1]))\n",
    "    compare_experiment_structure(ret[ARCHS[0]], ret[ARCHS[1]])\n",
    "    print('Comparing dataset %s with dataset %s' % (ARCHS[1], ARCHS[2]))\n",
    "    compare_experiment_structure(ret[ARCHS[1]], ret[ARCHS[2]])\n",
    "    # Check that images exist\n",
    "    for arch, arch_dict in ret.iteritems():\n",
    "        print('Checking result files for architecture %s' % arch)\n",
    "        print('Checking images for architecture %s' % arch)\n",
    "        check_images(arch, arch_dict)\n",
    "    \n",
    "    return ret\n",
    "\n",
    "def compare_experiment_structure(a, b):\n",
    "    '''\n",
    "    Check that the experiments in dictionary a match with those in b. Report inconsistencies\n",
    "    '''\n",
    "    for dataset_label in a.iterkeys():\n",
    "        for model_label in a[dataset_label]:\n",
    "            if dataset_label not in b.keys() or model_label not in b[dataset_label]:\n",
    "                warn('Found experiment (data=%s, model=%s) in first dictionary but not second' \\\n",
    "                     % (dataset_label, model_label))\n",
    "    for dataset_label in b.iterkeys():\n",
    "        for model_label in b[dataset_label]:\n",
    "            if dataset_label not in a.keys() or model_label not in a[dataset_label]:\n",
    "                warn('Found experiment (data: %s, model: %s) in second dictionary but not first' \\\n",
    "                     % (dataset_label, model_label))\n",
    "\n",
    "def check_result_files(arch, a):\n",
    "    '''\n",
    "    Check that exactly one npz file exists in each experiment in dictionary a\n",
    "    '''\n",
    "    for dataset_label in a.iterkeys():\n",
    "        for model_label in a[dataset_label]:\n",
    "            result_root = os.path.join(RESULTS_ROOTS[arch], 'data=%s' % dataset_label, 'model=%s' % model_label)\n",
    "            if not os.path.isdir(result_root):\n",
    "                warn('Result directory does not exist for (arch: %s, data: %s, model: %s)' \\\n",
    "                     % (arch, dataset_label, model_label))\n",
    "            else:\n",
    "                npz_files = [x for x in os.path.listdir(result_root) if x.endswith('.npz')]\n",
    "                if len(npz_files) == 0:\n",
    "                    warn('No .npz files found for (arch: %s, data: %s, model: %s)' \\\n",
    "                     % (arch, dataset_label, model_label))\n",
    "                elif len(npz_files) > 1:\n",
    "                    warn('Too many .npz files found for (arch: %s, data: %s, model: %s)' \\\n",
    "                     % (arch, dataset_label, model_label))\n",
    "                \n",
    "def check_images(arch, a):\n",
    "    '''\n",
    "    Check that the images for experiments in dictionary a exist\n",
    "    '''\n",
    "    for dataset_label in a.iterkeys():\n",
    "        for model_label in a[dataset_label]:\n",
    "            image_root = os.path.join(IMAGE_ROOTS[arch], 'data=%s' % dataset_label, 'model=%s' % model_label)\n",
    "            if not os.path.isdir(image_root):\n",
    "                warn('Image directory does not exist for (arch: %s, data: %s, model: %s)' \\\n",
    "                     % (arch, dataset_label, model_label))\n",
    "            else:\n",
    "                image_names = [x for x in os.listdir(image_root) if x.endswith('.gif')]\n",
    "                if len(image_names) == 0:\n",
    "                    warn('No images found for (arch: %s, data: %s, model: %s)' \\\n",
    "                         % (arch, dataset_label, model_label))\n",
    "\n",
    "                    \n",
    "def get_results(arch, dataset_label, model_label):\n",
    "    '''\n",
    "    Retrieve results array\n",
    "    '''\n",
    "    results_dir = os.path.join(RESULTS_ROOTS[arch], 'data=%s' % dataset_label, 'model=%s' % model_label)\n",
    "    if not os.path.isdir(results_dir):\n",
    "        raise RuntimeError('Path does not exist: %s' % results_dir)\n",
    "    results_file_arr = filter(lambda x: x.endswith('.npz'), os.listdir(results_dir))\n",
    "    if len(results_file_arr) == 0:\n",
    "        raise RuntimeError('No results file found in path %s' % results_dir)\n",
    "    elif len(results_file_arr) > 1:\n",
    "        raise RuntimeError('Too many results files found in path %s' % results_dir)\n",
    "    results_file_path = os.path.join(results_dir, results_file_arr[0])\n",
    "    return np.load(results_file_path, mmap_mode='r')\n",
    "\n",
    "\n",
    "def get_sorted_videos_by_metric(arch, dataset_label, model_label, metric):\n",
    "    '''\n",
    "    Get the list of videos sorted by the sum of the given metric over all time steps\n",
    "    '''\n",
    "    results = get_results(arch, dataset_label, model_label)\n",
    "    metric_vals = results[metric]\n",
    "    metric_aucs = np.sum(metric_vals, axis=1)\n",
    "    sorted_idx = np.argsort(metric_aucs)\n",
    "    return sorted_idx, metric_aucs[sorted_idx]\n",
    "\n",
    "\n",
    "def plot_sorted_auc(ax, arch, dataset_label, model_label, metric, label, max_value=1.0, linestyle=None, color=None):\n",
    "    '''\n",
    "    Plot ranked AUC plot. max_value specifies the maximum area under the plot if plotting normalized\n",
    "    AUC is desired.\n",
    "    '''\n",
    "    # Plot\n",
    "    _, sorted_metric_aucs = get_sorted_videos_by_metric(arch, dataset_label, model_label, metric)\n",
    "    ax.plot(xrange(len(sorted_metric_aucs)), sorted_metric_aucs / float(max_value), label=label, linestyle=linestyle, color=color)\n",
    "\n",
    "\n",
    "def plot_arch_comparison(dataset_label, model_label, metric, max_value=1.0):\n",
    "    '''\n",
    "    Plot the ranked performance plot between each architecture for a given train/test set combination\n",
    "    '''\n",
    "    display(HTML('<hr style=\"height:2px\">'))\n",
    "    display(HTML('<h1>Train:%s<br>Test:%s</h1>' % (model_label, dataset_label)))\n",
    "    \n",
    "    \n",
    "    fig = plt.figure()\n",
    "    ax1 = fig.add_subplot(111)\n",
    "    for arch in ARCHS:\n",
    "        plot_sorted_auc(ax1, arch, dataset_label, model_label, metric, arch, max_value=max_value)\n",
    "    ax1.set_xlabel('Instance #')\n",
    "    ax1.set_ylabel('%s AUC' % metric.upper())\n",
    "    ax1.legend(loc='lower left', bbox_to_anchor=(1, 0))\n",
    "    ax1.set_title('Architecture comparison\\nTraining set: %s\\nTesting set: %s' % (model_label, dataset_label))\n",
    "    plt.show()\n",
    "    \n",
    "    for arch in ARCHS:\n",
    "        display(Markdown('## Architecture: %s' % arch))\n",
    "        sorted_idx, _ = get_sorted_videos_by_metric(arch, dataset_label, model_label, metric)\n",
    "        visualize_videos(arch, dataset_label, model_label, sorted_idx)\n",
    "\n",
    "\n",
    "def plot_training_set_comparison(exps, dataset_label, metric, max_value=1.0):\n",
    "    '''\n",
    "    Plot performance of all models that were tested on the given dataset on one graph.\n",
    "    '''\n",
    "    \n",
    "    display(HTML('<hr style=\"height:2px\">'))\n",
    "    display(HTML('<h1>Test:%s</h1>' % (dataset_label)))\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    ax1 = fig.add_subplot(111)\n",
    "    \n",
    "    for arch in ARCHS:\n",
    "        if dataset_label not in exps[arch]:\n",
    "            warn('Did not find dataset %s for architecture %s, skipping' % (dataset_label, arch))\n",
    "            continue\n",
    "        model_labels = exps[arch][dataset_label]\n",
    "\n",
    "        # Plot\n",
    "        for model_label in model_labels:\n",
    "            plot_sorted_auc(ax1, arch, dataset_label, model_label, metric,\n",
    "                            'arch=%s,train=%s' % (arch, model_label), max_value=max_value)\n",
    "    \n",
    "    # Format plot\n",
    "    display(HTML('<h2>Sorted SSIM AUC graph</h2>'))\n",
    "    ax1.set_xlabel('Instance #')\n",
    "    ax1.set_ylabel('%s AUC' % metric.upper())\n",
    "    ax1.legend(loc='lower left', bbox_to_anchor=(1, 0))\n",
    "    ax1.set_title('Training set comparison\\nTesting set: %s' % dataset_label)\n",
    "    plt.show()\n",
    "    \n",
    "    for arch in ARCHS:\n",
    "        if dataset_label not in exps[arch]:\n",
    "            warn('Did not find dataset %s for architecture %s, skipping' % (dataset_label, arch))\n",
    "            continue\n",
    "        model_labels = exps[arch][dataset_label]\n",
    "\n",
    "        for model_label in model_labels:\n",
    "            # Show videos\n",
    "            display(HTML('<h2>Architecture: %s<br>Train: %s</h2>' % (arch, model_label)))\n",
    "            sorted_idx, _ = get_sorted_videos_by_metric(arch, dataset_label, model_label, metric)\n",
    "            visualize_videos(arch, dataset_label, model_label, sorted_idx)\n",
    "\n",
    "\n",
    "def summarize_experiment(arch, dataset_label, model_label, metric, max_value=1.0):\n",
    "    '''\n",
    "    Show the ranked AUC plot and videos for one experiment.\n",
    "    '''\n",
    "    display(HTML('<hr style=\"height:2px\">'))\n",
    "    display(HTML('<h2>Architecture: %s<br>Train:%s<br>Test:%s</h2>' \\\n",
    "                % (arch, model_label, dataset_label)))\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    ax1 = fig.add_subplot(111)\n",
    "    plot_sorted_auc(ax1, arch, dataset_label, model_label, metric, None, max_value=max_value)\n",
    "    ax1.set_xlabel('Instance #')\n",
    "    ax1.set_ylabel('%s AUC' % metric.upper())\n",
    "    plt.show()\n",
    "    \n",
    "    sorted_idx, _ = get_sorted_videos_by_metric(arch, dataset_label, model_label, metric)\n",
    "    visualize_videos(arch, dataset_label, model_label, sorted_idx)\n",
    "\n",
    "\n",
    "def summarize_discriminator_output(dataset_label, model_label, use_zscore=False):\n",
    "    '''\n",
    "    Plot the discriminator score of MCNet for the given training and test set.\n",
    "    Only valid for long-term video datasets\n",
    "    '''\n",
    "    assert(dataset_label.endswith('_long'))\n",
    "    \n",
    "    display(HTML('<hr style=\"height:2px\">'))\n",
    "    display(HTML('<h2>Train:%s<br>Test:%s</h2>' \\\n",
    "                % (model_label, dataset_label)))\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    ax1 = fig.add_subplot(111)\n",
    "    results = get_results('mcnet', dataset_label, model_label)\n",
    "    # Skip first column, which is zeros for some reason\n",
    "    disc_output = results['disc_output'][:, 1:]\n",
    "    display(Markdown('*Mean output: %.05f *' % np.mean(disc_output)))\n",
    "    if use_zscore:\n",
    "        disc_output = zscore(disc_output)\n",
    "    # Define zero-indexed frame indexes for discriminator output\n",
    "    frame_indexes = np.arange(disc_output.shape[1]) + 15 + 1\n",
    "    sorted_idx, _ = get_sorted_videos_by_metric('mcnet', dataset_label, model_label, 'ssim')\n",
    "    \n",
    "    for inv_rank in xrange(5):\n",
    "        video_idx = sorted_idx[inv_rank]\n",
    "        rank = len(sorted_idx) - inv_rank\n",
    "        disc_output_cur_vid = disc_output[video_idx, :]\n",
    "        ax1.plot(frame_indexes[::10], disc_output_cur_vid[::10], label='%04d (rank %d)' % (video_idx, rank))\n",
    "\n",
    "    for inv_rank in xrange(len(sorted_idx)-5,len(sorted_idx)):\n",
    "        video_idx = sorted_idx[inv_rank]\n",
    "        rank = len(sorted_idx) - inv_rank\n",
    "        disc_output_cur_vid = disc_output[video_idx, :]\n",
    "        ax1.plot(frame_indexes[::10], disc_output_cur_vid[::10], label='%04d (rank %d)' % (video_idx, rank), linestyle=':')\n",
    "\n",
    "    # Plot mean discriminator score over time\n",
    "    mean_output = np.mean(disc_output, axis=0)\n",
    "    ax1.plot(frame_indexes[::10], mean_output[::10], label='mean', linestyle='--')\n",
    "        \n",
    "    # Format plot\n",
    "    ax1.legend(loc='lower left', bbox_to_anchor=(1, 0))\n",
    "    ax1.set_xlim([16, 500])\n",
    "    ax1.set_xlabel('Frame index (0 = first GT frame)')\n",
    "    if use_zscore:\n",
    "        ax1.set_ylabel('Discriminator output (z-scored)')\n",
    "        ax1.set_title('Discriminator output for long-term videos (z-scored)\\nTraining set: %s\\nTesting set: %s' \\\n",
    "                     % (model_label, dataset_label) )\n",
    "    else:\n",
    "        ax1.set_ylabel('Discriminator output')\n",
    "        ax1.set_title('Discriminator output for long-term videos\\nTraining set: %s\\nTesting set: %s' \\\n",
    "                     % (model_label, dataset_label) )\n",
    "    plt.show()\n",
    "    \n",
    "    # Show examples\n",
    "    visualize_videos('mcnet', dataset_label, model_label, sorted_idx)\n",
    "\n",
    "def zscore(a):\n",
    "    mean = np.mean(a)\n",
    "    std = np.std(a)\n",
    "    return (a - mean) / std\n",
    "\n",
    "\n",
    "def plot_arbitrary_experiments(archs, dataset_labels, model_labels, metric, ylim=None, linestyles=None, colors=None):\n",
    "    assert(len(archs) == len(dataset_labels)\n",
    "           and len(archs) == len(model_labels)\n",
    "           and (linestyles is None or len(archs) == len(linestyles))\n",
    "           and (colors is None or len(archs) == len(colors)))\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax1 = fig.add_subplot(111)\n",
    "\n",
    "    for i in xrange(len(archs)):\n",
    "        arch = archs[i]\n",
    "        dataset_label = dataset_labels[i]\n",
    "        model_label = model_labels[i]\n",
    "        linestyle = None if linestyles is None else linestyles[i]\n",
    "        color = None if colors is None else colors[i]\n",
    "\n",
    "        label = 'arch=%s,data=%s,model=%s' % (arch, dataset_label, model_label)\n",
    "        plot_sorted_auc(ax1, arch, dataset_label, model_label, metric, label, max_value=5, linestyle=linestyle, color=color)\n",
    "\n",
    "    if ylim is not None:\n",
    "        ax1.set_ylim(ylim)\n",
    "    ax1.set_xlabel('Instance #')\n",
    "    ax1.set_ylabel('%s AUC' % metric.upper())\n",
    "    ax1.legend(loc='lower left', bbox_to_anchor=(1, 0))\n",
    "    plt.show()\n",
    "\n",
    "    for i in xrange(len(archs)):\n",
    "        arch = archs[i]\n",
    "        dataset_label = dataset_labels[i]\n",
    "        model_label = model_labels[i]\n",
    "\n",
    "        display(HTML('<h3>Arch: %s<br>Train: %s<br>Test: %s</h3>' % (arch, model_label, dataset_label)))\n",
    "        sorted_idx, _ = get_sorted_videos_by_metric(arch, dataset_label, model_label, metric)\n",
    "        visualize_videos(arch, dataset_label, model_label, sorted_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read and validate the experiments on disk (MUST RUN BEFORE PLOTTING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = load_experiments()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debug individual plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_arch_comparison('flashing=async_b+num_digits=2', 'flashing=async_a+num_digits=2', 'ssim')\n",
    "# plot_training_set_comparison(experiments, 'flashing=async_b+num_digits=2', 'ssim')\n",
    "# summarize_experiment('mcnet', 'translation=on+num_digits=2', 'translation=on', 'ssim')\n",
    "# summarize_discriminator_output('rotation=no_limit+num_digits=2_long', 'rotation=no_limit', use_zscore=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Short-term evaluation\n",
    "\n",
    "The cell below shows the results of short-term prediction (i.e. given the first 10 frames, predict the next 5) for each test set. Note that this evaluates over the same time-steps that the model was trained on. Each plot corresponds to one test dataset, and shows the ranked AUC plot for every model that was evaluated on that dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_dataset_labels = [x.replace('data=', '') for x in os.listdir(RESULTS_ROOTS['mcnet']) if not x.endswith('_long')]\n",
    "for dataset_label in test_dataset_labels:\n",
    "    plot_training_set_comparison(experiments, dataset_label, 'ssim', max_value=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Long-term evaluation\n",
    "\n",
    "The cell below shows the results of long-term prediction (i.e. given the first 10 frames, predict the next 490 frames) for each test set. Since the models were only trained to predict the next 5 frames, this explores how well the learned short-term dynamics fit the long-term dynamics. Each plot corresponds to one test dataset, and shows the ranked AUC plot for every model that was evaluated on that dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_dataset_labels = [x.replace('data=', '') for x in os.listdir(RESULTS_ROOTS['mcnet']) if x.endswith('_long')]\n",
    "for dataset_label in test_dataset_labels:\n",
    "    plot_training_set_comparison(experiments, dataset_label, 'ssim', max_value=485)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discriminator scores for long-term prediction\n",
    "\n",
    "The MCNet discriminator takes as input a 15-frame sequence, and outputs a value in [0, 1] corresponding to the confidence that the input is a real (not-generated) sequence (i.e. a real sequence should have confidence 1). To generate the plots below, a sliding window provides input for the discriminator. The x-axis indicates the index of the last frame in the input sequence, and the y-axis is the z-score of the current output over all discriminator scores in the video set. Each plot shows the output for the worst three videos (solid lines) and the best three videos (dotted lines). The plot labeled \"mean\" shows the average discriminator response across all frames at a given time step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for dataset_label in experiments['mcnet']:\n",
    "    if not dataset_label.endswith('_long'): continue\n",
    "    for model_label in experiments['mcnet'][dataset_label]:\n",
    "        summarize_discriminator_output(dataset_label, model_label, use_zscore=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discriminator scores for long-term prediction (diagonal experiments only)\n",
    "\n",
    "Discriminator scores might be less useful for the extrapolation experiments. The plots below only show experiments where the training and testing sets were generated from the same parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for dataset_label in experiments['mcnet']:\n",
    "    if not dataset_label.endswith('_long'): continue\n",
    "    for model_label in experiments['mcnet'][dataset_label]:\n",
    "        if dataset_label == model_label + '_long':\n",
    "            summarize_discriminator_output(dataset_label, model_label, use_zscore=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summaries of \"diagonal\" experiments\n",
    "\n",
    "These plots summarize the experiments where the training and testing sets were generated from the same parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for arch in ARCHS:\n",
    "    # Get all models for the current architecture\n",
    "    model_labels = []\n",
    "    for dataset_label in experiments[arch].iterkeys():\n",
    "        # Check that any model was trained on the current dataset\n",
    "        if dataset_label in experiments[arch][dataset_label]:\n",
    "            model_labels.append(dataset_label)\n",
    "\n",
    "    for model_label in model_labels:\n",
    "        try:\n",
    "            summarize_experiment(arch, model_label, model_label, 'ssim', max_value=5)\n",
    "        except RuntimeError:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment sandbox\n",
    "\n",
    "The area below is for plotting arbitrary experiments on the same plot. Content will change frequently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "metric = 'ssim'\n",
    "\n",
    "# Learning: 1 digit\n",
    "display(Markdown('# Learning dynamics: 1 digit'))\n",
    "\n",
    "archs = 6 * ['mcnet'] + 6 * ['prednet'] + 6 * ['drnet']\n",
    "dataset_labels = 3 * ['translation=on', 'rotation=limit_a', 'rotation=no_limit', 'rotation=cw', 'scale=limit_a', 'flashing=sync_b']\n",
    "model_labels = 3 * ['translation=on', 'rotation=limit_a', 'rotation=no_limit', 'rotation=cw', 'scale=limit_a', 'flashing=sync_b']\n",
    "linestyles = 6 * [None] + 6 * ['--'] + 6 * ['-.']\n",
    "plot_arbitrary_experiments(archs, dataset_labels, model_labels, metric, ylim=[0.94, 1.005], linestyles=linestyles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Extrapolation: 1 digit\n",
    "display(Markdown('# Extrapolating dynamics: 1 digit'))\n",
    "\n",
    "archs = 2 * ['mcnet'] + 2 * ['prednet'] + 2 * ['drnet']\n",
    "dataset_labels = 3 * ['rotation=limit_b', 'scale=limit_a']\n",
    "model_labels = 3 * ['rotation=limit_a', 'scale=limit_b']\n",
    "linestyles = 2 * [None] + 2 * ['--'] + 2 * ['-.']\n",
    "plot_arbitrary_experiments(archs, dataset_labels, model_labels, metric, linestyles=linestyles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning: 2 digits\n",
    "display(Markdown('# Learning dynamics: 2 digits'))\n",
    "\n",
    "display(Markdown('## MCNet'))\n",
    "archs = 7 * ['mcnet'] + 7 * ['prednet'] + 7 * ['drnet']\n",
    "dataset_labels = 3 * ['translation=on+num_digits=2', 'rotation=limit_a+num_digits=2', 'rotation=no_limit+num_digits=2', 'rotation=cw+num_digits=2', 'scale=limit_a+num_digits=2', 'flashing=sync_b+num_digits=2', 'flashing=async_b+num_digits=2']\n",
    "model_labels = dataset_labels\n",
    "linestyles = 7 * [None] + 7 * ['--'] + 7 * ['-.']\n",
    "plot_arbitrary_experiments(archs, dataset_labels, model_labels, metric, ylim=[.94, 1.005], linestyles=linestyles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Learning: 3 digits\n",
    "display(Markdown('# Learning dynamics: 3 digits'))\n",
    "\n",
    "display(Markdown('## MCNet'))\n",
    "archs = 7 * ['mcnet'] + 7 * ['prednet'] + 7 * ['drnet']\n",
    "dataset_labels = 3 * ['translation=on+num_digits=3', 'rotation=limit_a+num_digits=3', 'rotation=no_limit+num_digits=3', 'rotation=cw+num_digits=3', 'scale=limit_a+num_digits=3', 'flashing=sync_b+num_digits=3', 'flashing=async_b+num_digits=3']\n",
    "model_labels = dataset_labels\n",
    "linestyles = 7 * [None] + 7 * ['--'] + 7 * ['-.']\n",
    "plot_arbitrary_experiments(archs, dataset_labels, model_labels, metric, ylim=[.94, 1.005], linestyles=linestyles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display(Markdown('# Extrapolating dynamics: 1 digit'))\n",
    "\n",
    "display(Markdown('## Rotation'))\n",
    "archs = 2 * ['mcnet'] + 2 * ['prednet'] + 2 * ['drnet']\n",
    "dataset_labels = 3 * ['rotation=limit_b', 'rotation=limit_a']\n",
    "model_labels = 6 * ['rotation=limit_a']\n",
    "linestyles = 2 * [None] + 2 * ['--'] + 2 * ['-.']\n",
    "plot_arbitrary_experiments(archs, dataset_labels, model_labels, metric, linestyles=linestyles)\n",
    "\n",
    "display(Markdown('## Scale'))\n",
    "archs = 2 * ['mcnet'] + 2 * ['prednet'] + 2 * ['drnet']\n",
    "dataset_labels = 6 * ['scale=limit_a']\n",
    "model_labels = 3 * ['scale=limit_a', 'scale=limit_b']\n",
    "linestyles = 2 * [None] + 2 * ['--'] + 2 * ['-.']\n",
    "plot_arbitrary_experiments(archs, dataset_labels, model_labels, metric, linestyles=linestyles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# display(Markdown('# Extrapolating dynamics: 2 digits'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display(Markdown('# Extrapolating number of digits: 1 digit -> 2 digits'))\n",
    "\n",
    "display(Markdown('## MCNet'))\n",
    "archs = 8 * ['mcnet']\n",
    "dataset_labels = 2 * ['translation=on+num_digits=2'] + 2 * ['rotation=limit_a+num_digits=2'] + 2 * ['rotation=no_limit+num_digits=2'] + 2 * ['scale=limit_a+num_digits=2']\n",
    "model_labels = ['translation=on', 'translation=on+num_digits=2', 'rotation=limit_a', 'rotation=limit_a+num_digits=2', 'rotation=no_limit', 'rotation=no_limit+num_digits=2', 'scale=limit_a', 'scale=limit_a+num_digits=2']\n",
    "linestyles = 4 * [':', None]\n",
    "colors = ['C0', 'C0', 'C1', 'C1', 'C2', 'C2', 'C3', 'C3']\n",
    "plot_arbitrary_experiments(archs, dataset_labels, model_labels, metric, ylim=[.88, 1.005], linestyles=linestyles, colors=colors)\n",
    "\n",
    "display(Markdown('## PredNet'))\n",
    "archs = 6 * ['prednet']\n",
    "dataset_labels = 2 * ['rotation=limit_a+num_digits=2'] + 2 * ['rotation=no_limit+num_digits=2'] + 2 * ['scale=limit_a+num_digits=2']\n",
    "model_labels = ['rotation=limit_a', 'rotation=limit_a+num_digits=2', 'rotation=no_limit', 'rotation=no_limit+num_digits=2', 'scale=limit_a', 'scale=limit_a+num_digits=2']\n",
    "linestyles = 3 * [':', None]\n",
    "colors = ['C0', 'C0', 'C1', 'C1', 'C2', 'C2']\n",
    "plot_arbitrary_experiments(archs, dataset_labels, model_labels, metric, ylim=[.88, 1.005], linestyles=linestyles, colors=colors)\n",
    "\n",
    "display(Markdown('## DrNet'))\n",
    "archs = 8 * ['drnet']\n",
    "dataset_labels = 2 * ['translation=on+num_digits=2'] + 2 * ['rotation=limit_a+num_digits=2'] + 2 * ['rotation=no_limit+num_digits=2'] + 2 * ['scale=limit_a+num_digits=2']\n",
    "model_labels = ['translation=on', 'translation=on+num_digits=2', 'rotation=limit_a', 'rotation=limit_a+num_digits=2', 'rotation=no_limit', 'rotation=no_limit+num_digits=2', 'scale=limit_a', 'scale=limit_a+num_digits=2']\n",
    "linestyles = 4 * [':', None]\n",
    "colors = ['C0', 'C0', 'C1', 'C1', 'C2', 'C2', 'C3', 'C3']\n",
    "plot_arbitrary_experiments(archs, dataset_labels, model_labels, metric, ylim=[.88, 1.005], linestyles=linestyles, colors=colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display(Markdown('# Extrapolating number of digits: 2 digits -> 1 digit'))\n",
    "\n",
    "display(Markdown('## MCNet'))\n",
    "archs = 8 * ['mcnet']\n",
    "dataset_labels = 2 * ['translation=on'] + 2 * ['rotation=limit_a'] + 2 * ['rotation=no_limit'] + 2 * ['scale=limit_a']\n",
    "model_labels = ['translation=on', 'translation=on+num_digits=2', 'rotation=limit_a', 'rotation=limit_a+num_digits=2', 'rotation=no_limit', 'rotation=no_limit+num_digits=2', 'scale=limit_a', 'scale=limit_a+num_digits=2']\n",
    "linestyles = 4 * [':', None]\n",
    "colors = ['C0', 'C0', 'C1', 'C1', 'C2', 'C2', 'C3', 'C3']\n",
    "plot_arbitrary_experiments(archs, dataset_labels, model_labels, metric, ylim=[.88, 1.005], linestyles=linestyles, colors=colors)\n",
    "\n",
    "display(Markdown('## PredNet'))\n",
    "archs = 6 * ['prednet']\n",
    "dataset_labels = 2 * ['rotation=limit_a'] + 2 * ['rotation=no_limit'] + 2 * ['scale=limit_a']\n",
    "model_labels = ['rotation=limit_a', 'rotation=limit_a+num_digits=2', 'rotation=no_limit', 'rotation=no_limit+num_digits=2', 'scale=limit_a', 'scale=limit_a+num_digits=2']\n",
    "linestyles = 3 * [':', None]\n",
    "colors = ['C0', 'C0', 'C1', 'C1', 'C2', 'C2']\n",
    "plot_arbitrary_experiments(archs, dataset_labels, model_labels, metric, ylim=[.93, 1.005], linestyles=linestyles, colors=colors)\n",
    "\n",
    "display(Markdown('## DrNet'))\n",
    "archs = 8 * ['drnet']\n",
    "dataset_labels = 2 * ['translation=on'] + 2 * ['rotation=limit_a'] + 2 * ['rotation=no_limit'] + 2 * ['scale=limit_a']\n",
    "model_labels = ['translation=on', 'translation=on+num_digits=2', 'rotation=limit_a', 'rotation=limit_a+num_digits=2', 'rotation=no_limit', 'rotation=no_limit+num_digits=2', 'scale=limit_a', 'scale=limit_a+num_digits=2']\n",
    "linestyles = 4 * [':', None]\n",
    "colors = ['C0', 'C0', 'C1', 'C1', 'C2', 'C2', 'C3', 'C3']\n",
    "plot_arbitrary_experiments(archs, dataset_labels, model_labels, metric, ylim=[.88, 1.005], linestyles=linestyles, colors=colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display(Markdown('# Extrapolating identity: one digit'))\n",
    "\n",
    "display(Markdown('## MCnet translation/scale/flashing'))\n",
    "archs = 6 * ['mcnet']\n",
    "dataset_labels = []\n",
    "dataset_labels_temp = ['translation=on', 'scale=limit_a', 'flashing=sync_b']\n",
    "for dataset_label in dataset_labels_temp:\n",
    "    dataset_labels += [dataset_label, dataset_label + '+image=label_subset_b']\n",
    "model_labels = [x.replace('label_subset_b', 'label_subset_a') for x in dataset_labels]\n",
    "linestyles = 3 * [None, ':']\n",
    "colors = ['C0', 'C0', 'C1', 'C1', 'C2', 'C2']\n",
    "plot_arbitrary_experiments(archs, dataset_labels, model_labels, metric, ylim=[.94, 1.005], linestyles=linestyles, colors=colors)\n",
    "\n",
    "display(Markdown('## MCNet rotation'))\n",
    "archs = 6 * ['mcnet']\n",
    "dataset_labels = []\n",
    "dataset_labels_temp = ['rotation=limit_a', 'rotation=no_limit', 'rotation=cw']\n",
    "for dataset_label in dataset_labels_temp:\n",
    "    dataset_labels += [dataset_label, dataset_label + '+image=label_subset_b']\n",
    "model_labels = [x.replace('label_subset_b', 'label_subset_a') for x in dataset_labels]\n",
    "linestyles = 3 * [None, ':']\n",
    "colors = ['C%d' % x for x in xrange(3) for _ in xrange(2)]\n",
    "plot_arbitrary_experiments(archs, dataset_labels, model_labels, metric, ylim=[.94, 1.005], linestyles=linestyles, colors=colors)\n",
    "\n",
    "display(Markdown('## PredNet rotation/scale'))\n",
    "archs = 8 * ['prednet']\n",
    "dataset_labels = []\n",
    "dataset_labels_temp = ['scale=limit_a', 'rotation=limit_a', 'rotation=no_limit', 'rotation=cw']\n",
    "for dataset_label in dataset_labels_temp:\n",
    "    dataset_labels += [dataset_label, dataset_label + '+image=label_subset_b']\n",
    "model_labels = [x.replace('label_subset_b', 'label_subset_a') for x in dataset_labels]\n",
    "linestyles = 4 * [None, ':']\n",
    "colors = ['C%d' % x for x in xrange(4) for _ in xrange(2)]\n",
    "plot_arbitrary_experiments(archs, dataset_labels, model_labels, metric, ylim=[.94, 1.005], linestyles=linestyles, colors=colors)\n",
    "\n",
    "display(Markdown('## DrNet translation/scale/flashing'))\n",
    "archs = 6 * ['drnet']\n",
    "dataset_labels = []\n",
    "dataset_labels_temp = ['translation=on', 'scale=limit_a', 'flashing=sync_b']\n",
    "for dataset_label in dataset_labels_temp:\n",
    "    dataset_labels += [dataset_label, dataset_label + '+image=label_subset_b']\n",
    "model_labels = [x.replace('label_subset_b', 'label_subset_a') for x in dataset_labels]\n",
    "linestyles = 3 * [None, ':']\n",
    "colors = ['C0', 'C0', 'C1', 'C1', 'C2', 'C2']\n",
    "plot_arbitrary_experiments(archs, dataset_labels, model_labels, metric, ylim=[.94, 1.005], linestyles=linestyles, colors=colors)\n",
    "\n",
    "display(Markdown('## DrNet rotation'))\n",
    "archs = 6 * ['drnet']\n",
    "dataset_labels = []\n",
    "dataset_labels_temp = ['rotation=limit_a', 'rotation=no_limit', 'rotation=cw']\n",
    "for dataset_label in dataset_labels_temp:\n",
    "    dataset_labels += [dataset_label, dataset_label + '+image=label_subset_b']\n",
    "model_labels = [x.replace('label_subset_b', 'label_subset_a') for x in dataset_labels]\n",
    "linestyles = 3 * [None, ':']\n",
    "colors = ['C%d' % x for x in xrange(3) for _ in xrange(2)]\n",
    "plot_arbitrary_experiments(archs, dataset_labels, model_labels, metric, ylim=[.94, 1.005], linestyles=linestyles, colors=colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display(Markdown('# Extrapolating identity: two digits'))\n",
    "\n",
    "display(Markdown('## MCnet translation/scale/flashing'))\n",
    "archs = 6 * ['mcnet']\n",
    "dataset_labels = []\n",
    "dataset_labels_temp = ['translation=on', 'scale=limit_a', 'flashing=sync_b']\n",
    "dataset_labels_temp = [x + '+num_digits=2' for x in dataset_labels_temp]\n",
    "for dataset_label in dataset_labels_temp:\n",
    "    dataset_labels += [dataset_label, dataset_label + '+image=label_subset_b']\n",
    "model_labels = [x.replace('label_subset_b', 'label_subset_a') for x in dataset_labels]\n",
    "linestyles = 3 * [None, ':']\n",
    "colors = ['C0', 'C0', 'C1', 'C1', 'C2', 'C2']\n",
    "plot_arbitrary_experiments(archs, dataset_labels, model_labels, metric, ylim=[.94, 1.005], linestyles=linestyles, colors=colors)\n",
    "\n",
    "display(Markdown('## MCNet rotation'))\n",
    "archs = 6 * ['mcnet']\n",
    "dataset_labels = []\n",
    "dataset_labels_temp = ['rotation=limit_a', 'rotation=no_limit', 'rotation=cw']\n",
    "dataset_labels_temp = [x + '+num_digits=2' for x in dataset_labels_temp]\n",
    "for dataset_label in dataset_labels_temp:\n",
    "    dataset_labels += [dataset_label, dataset_label + '+image=label_subset_b']\n",
    "model_labels = [x.replace('label_subset_b', 'label_subset_a') for x in dataset_labels]\n",
    "linestyles = 3 * [None, ':']\n",
    "colors = ['C%d' % x for x in xrange(3) for _ in xrange(2)]\n",
    "plot_arbitrary_experiments(archs, dataset_labels, model_labels, metric, ylim=[.94, 1.005], linestyles=linestyles, colors=colors)\n",
    "\n",
    "display(Markdown('## PredNet rotation/scale'))\n",
    "archs = 8 * ['prednet']\n",
    "dataset_labels = []\n",
    "dataset_labels_temp = ['scale=limit_a', 'rotation=limit_a', 'rotation=no_limit', 'rotation=cw']\n",
    "dataset_labels_temp = [x + '+num_digits=2' for x in dataset_labels_temp]\n",
    "for dataset_label in dataset_labels_temp:\n",
    "    dataset_labels += [dataset_label, dataset_label + '+image=label_subset_b']\n",
    "model_labels = [x.replace('label_subset_b', 'label_subset_a') for x in dataset_labels]\n",
    "linestyles = 4 * [None, ':']\n",
    "colors = ['C%d' % x for x in xrange(4) for _ in xrange(2)]\n",
    "plot_arbitrary_experiments(archs, dataset_labels, model_labels, metric, ylim=[.94, 1.005], linestyles=linestyles, colors=colors)\n",
    "\n",
    "display(Markdown('## DrNet translation/scale/flashing'))\n",
    "archs = 6 * ['drnet']\n",
    "dataset_labels = []\n",
    "dataset_labels_temp = ['translation=on', 'scale=limit_a', 'flashing=sync_b']\n",
    "dataset_labels_temp = [x + '+num_digits=2' for x in dataset_labels_temp]\n",
    "for dataset_label in dataset_labels_temp:\n",
    "    dataset_labels += [dataset_label, dataset_label + '+image=label_subset_b']\n",
    "model_labels = [x.replace('label_subset_b', 'label_subset_a') for x in dataset_labels]\n",
    "linestyles = 3 * [None, ':']\n",
    "colors = ['C0', 'C0', 'C1', 'C1', 'C2', 'C2']\n",
    "plot_arbitrary_experiments(archs, dataset_labels, model_labels, metric, ylim=[.94, 1.005], linestyles=linestyles, colors=colors)\n",
    "\n",
    "display(Markdown('## DrNet rotation'))\n",
    "archs = 6 * ['drnet']\n",
    "dataset_labels = []\n",
    "dataset_labels_temp = ['rotation=limit_a', 'rotation=no_limit', 'rotation=cw']\n",
    "dataset_labels_temp = [x + '+num_digits=2' for x in dataset_labels_temp]\n",
    "for dataset_label in dataset_labels_temp:\n",
    "    dataset_labels += [dataset_label, dataset_label + '+image=label_subset_b']\n",
    "model_labels = [x.replace('label_subset_b', 'label_subset_a') for x in dataset_labels]\n",
    "linestyles = 3 * [None, ':']\n",
    "colors = ['C%d' % x for x in xrange(3) for _ in xrange(2)]\n",
    "plot_arbitrary_experiments(archs, dataset_labels, model_labels, metric, ylim=[.94, 1.005], linestyles=linestyles, colors=colors)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
